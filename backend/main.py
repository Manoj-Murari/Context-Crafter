print("--- I AM THE NEW AND IMPROVED ENGINE CODE! ---")

import os
import asyncio
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from fastapi.middleware.cors import CORSMiddleware
import aiofiles
import tempfile
import shutil
import subprocess
import time
from typing import List, Dict

# --- Configuration ---
DEFAULT_IGNORE_PATTERNS = {".git", ".svn", ".hg", ".vscode", ".idea", ".project", ".settings", "*.sublime-workspace", "node_modules", "vendor", "Pods", "venv", ".venv", "__pycache__", "*.pyc", "*.pyo", "*.pyd", "build", "dist", "target", "out", ".DS_Store", "Thumbs.db", "*.log", ".env"}
BINARY_EXTENSIONS = {".png", ".jpg", ".jpeg", ".gif", ".ico", ".svg", ".webp", ".pdf", ".zip", ".tar.gz", ".rar", ".7z", ".mp3", ".mp4", ".mov", ".avi", ".woff", ".woff2", ".eot", ".ttf", ".otf", ".exe", ".dll", ".so", ".a", ".lib", ".dmg", ".app"}
CHUNK_TOKEN_THRESHOLD = 15000

# --- Pydantic Models ---
class FilePayload(BaseModel):
    path: str
    content: str

class ProcessGitHubRequest(BaseModel):
    url: str
    mode: str

# NEW: Pydantic model for the local path request
class ProcessPathRequest(BaseModel):
    path: str
    mode: str

class ProcessFilesRequest(BaseModel):
    projectName: str
    files: List[FilePayload]
    mode: str

class ProcessResponse(BaseModel):
    tree: str
    token_estimate: int
    is_chunked: bool = Field(alias="isChunked")
    chunks: List[str]

# --- FastAPI App Initialization ---
app = FastAPI()
origins = ["http://localhost", "http://localhost:5173", "http://127.0.0.1:5173"]
app.add_middleware(CORSMiddleware, allow_origins=origins, allow_credentials=True, allow_methods=["*"], allow_headers=["*"])

# --- Helper Functions: The actual brainpower ---

async def parse_gitignore(root_path: str) -> set:
    """Finds and parses the .gitignore file."""
    gitignore_path = os.path.join(root_path, ".gitignore")
    patterns = set()
    if os.path.exists(gitignore_path):
        try:
            async with aiofiles.open(gitignore_path, "r", encoding="utf-8", errors="ignore") as f:
                async for line in f:
                    stripped_line = line.strip()
                    if stripped_line and not stripped_line.startswith("#"):
                        patterns.add(stripped_line)
        except Exception:
            pass # Ignore errors reading gitignore
    return patterns

def is_ignored(path: str, root_path: str, gitignore_patterns: set, ignore_patterns: set) -> bool:
    """Checks if a file or directory should be ignored."""
    relative_path = os.path.relpath(path, root_path).replace("\\", "/")
    
    # Check against the main name first, e.g., '.git' directory itself
    if os.path.basename(path) in ignore_patterns:
        return True

    parts = relative_path.split("/")
    for i in range(len(parts)):
        subpath = "/".join(parts[i:])
        if subpath in gitignore_patterns or parts[i] in ignore_patterns:
            return True
            
    if os.path.isfile(path):
        _, ext = os.path.splitext(path)
        if ext.lower() in BINARY_EXTENSIONS:
            return True
    return False

def is_file_ignored(relative_path: str, ignore_patterns: set) -> bool:
    """Checks if a single file should be ignored based on its path."""
    parts = relative_path.split("/")
    for part in parts:
        if part in ignore_patterns:
            return True
    _, ext = os.path.splitext(relative_path)
    if ext.lower() in BINARY_EXTENSIONS:
        return True
    return False

def build_tree_from_paths(project_name: str, file_paths: List[str]) -> str:
    """Builds a directory tree string from a list of relative file paths."""
    tree = {}
    for path in sorted(file_paths):
        parts = path.split('/')
        current_level = tree
        for part in parts[:-1]:
            current_level = current_level.setdefault(part, {})
        current_level[parts[-1]] = None

    def generate_tree_lines(d, indent=''):
        lines = []
        items = sorted(d.items())
        for i, (name, content) in enumerate(items):
            connector = '├── '
            lines.append(f"{indent}{connector}{name}{'/' if content is not None else ''}")
            if content is not None:
                lines.extend(generate_tree_lines(content, indent + '│   '))
        return lines

    tree_str = f"{project_name}\n" + "\n".join(generate_tree_lines(tree))
    return tree_str

def process_and_chunk_prompt(project_name: str, tree_str: str, contents_map: Dict[str, str]) -> ProcessResponse:
    """Takes project data and returns a chunked or unchunked response."""
    file_content_parts = []
    for path, content in contents_map.items():
        lang = os.path.splitext(path)[1].lstrip('.')
        file_content_parts.append(f"\n---\n### `{path}`\n\n```{lang}\n{content}\n```")

    initial_prompt = (
        f"# Project Context for: {project_name}\n\n"
        "This context package was intelligently generated by Context Crafter...\n"
        "## Project Structure\n\n```\n" + tree_str + "\n```\n\n"
        "## File Contents\n\nThe contents of each file are provided below..."
    )

    full_prompt = initial_prompt + "".join(file_content_parts)
    token_estimate = len(full_prompt) // 4

    if token_estimate < CHUNK_TOKEN_THRESHOLD:
        return ProcessResponse(tree=tree_str, token_estimate=token_estimate, isChunked=False, chunks=[full_prompt])

    chunks = []
    current_chunk = initial_prompt
    for file_part in file_content_parts:
        if (len(current_chunk) + len(file_part)) // 4 > CHUNK_TOKEN_THRESHOLD and current_chunk != initial_prompt:
            chunks.append(current_chunk)
            current_chunk = ""
        current_chunk += file_part
    
    if current_chunk:
        chunks.append(current_chunk)

    total_chunks = len(chunks)
    if not chunks:
        chunks.append(initial_prompt)

    chunks[0] = f"I am providing the context for a project named '{project_name}' in {total_chunks} parts. Acknowledge each part by saying 'RECEIVED PART X of {total_chunks}' and wait for the final part before summarizing.\n\nPart 1 of {total_chunks}:\n\n{chunks[0]}"
    if total_chunks > 1:
        chunks[-1] = f"{chunks[-1]}\n\nALL CONTEXT PROVIDED. Please confirm you have received all {total_chunks} parts."

    return ProcessResponse(tree=tree_str, token_estimate=token_estimate, isChunked=True, chunks=chunks)


# --- API Endpoints ---
@app.post("/api/process-files", response_model=ProcessResponse)
async def process_files(request: ProcessFilesRequest):
    """Processes a list of files sent from the frontend."""
    try:
        ignore_list = DEFAULT_IGNORE_PATTERNS if request.mode == "intelligent" else set()
        
        filtered_files = [f for f in request.files if not is_file_ignored(f.path, ignore_list)]
        
        file_paths = [f.path for f in filtered_files]
        contents_map = {f.path: f.content for f in filtered_files}

        tree_str = build_tree_from_paths(request.projectName, file_paths)
        
        return process_and_chunk_prompt(request.projectName, tree_str, contents_map)

    except Exception as e:
        print(f"Error processing files: {e}")
        raise HTTPException(status_code=500, detail=f"An internal error occurred: {str(e)}")

# NEW: Endpoint for processing a local file path
@app.post("/api/process-path", response_model=ProcessResponse)
async def process_path(request: ProcessPathRequest):
    """Processes files from a given local directory path."""
    project_root = request.path
    if not os.path.isdir(project_root):
        raise HTTPException(status_code=400, detail="Invalid path: Not a directory.")
        
    try:
        project_name = os.path.basename(project_root)

        ignore_list = DEFAULT_IGNORE_PATTERNS if request.mode == "intelligent" else set()
        gitignore_patterns = await parse_gitignore(project_root) if request.mode == "intelligent" else set()

        contents_map = {}
        file_paths = []

        for dirpath, dirnames, filenames in os.walk(project_root, topdown=True):
            dirnames[:] = [d for d in sorted(dirnames) if not is_ignored(os.path.join(dirpath, d), project_root, gitignore_patterns, ignore_list)]
            
            for f_name in sorted(filenames):
                file_path = os.path.join(dirpath, f_name)
                if not is_ignored(file_path, project_root, gitignore_patterns, ignore_list):
                    relative_path = os.path.relpath(file_path, project_root).replace("\\", "/")
                    file_paths.append(relative_path)
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            contents_map[relative_path] = f.read()
                    except Exception:
                        continue

        tree_str = build_tree_from_paths(project_name, file_paths)
        return process_and_chunk_prompt(project_name, tree_str, contents_map)
        
    except Exception as e:
        print(f"Error processing path {project_root}: {e}")
        raise HTTPException(status_code=500, detail=f"An internal error occurred: {str(e)}")

@app.post("/api/process-github", response_model=ProcessResponse)
async def process_github(request: ProcessGitHubRequest):
    """Clones a GitHub repo and processes its files."""
    temp_dir = tempfile.mkdtemp()
    try:
        subprocess.run(["git", "clone", "--depth", "1", request.url, temp_dir], check=True, capture_output=True, text=True)
        
        project_root = temp_dir
        project_name = request.url.split('/')[-1].replace('.git', '')

        ignore_list = DEFAULT_IGNORE_PATTERNS if request.mode == "intelligent" else set()
        gitignore_patterns = await parse_gitignore(project_root) if request.mode == "intelligent" else set()

        contents_map = {}
        file_paths = []

        for dirpath, dirnames, filenames in os.walk(project_root):
            dirnames[:] = [d for d in sorted(dirnames) if not is_ignored(os.path.join(dirpath, d), project_root, gitignore_patterns, ignore_list)]
            
            for f_name in sorted(filenames):
                file_path = os.path.join(dirpath, f_name)
                if not is_ignored(file_path, project_root, gitignore_patterns, ignore_list):
                    relative_path = os.path.relpath(file_path, project_root).replace("\\", "/")
                    file_paths.append(relative_path)
                    try:
                        with open(file_path, "r", encoding="utf-8", errors="ignore") as f:
                            contents_map[relative_path] = f.read()
                    except Exception:
                        continue

        tree_str = build_tree_from_paths(project_name, file_paths)
        return process_and_chunk_prompt(project_name, tree_str, contents_map)

    except subprocess.CalledProcessError as e:
        raise HTTPException(status_code=400, detail=f"Failed to clone repository. Is the URL correct? Error: {e.stderr}")
    except FileNotFoundError:
        raise HTTPException(status_code=500, detail="Git command not found on the server.")
    except Exception as e:
        print(f"Error processing GitHub repo: {e}")
        raise HTTPException(status_code=500, detail=f"An internal error occurred: {str(e)}")
    finally:
        for i in range(3): # Try 3 times
            try:
                shutil.rmtree(temp_dir)
                break
            except PermissionError:
                time.sleep(0.1) # Wait a little bit
            except Exception:
                break

@app.get("/")
def read_root():
    return {"message": "Hello from the Context Crafter Engine Room! We are running!"}